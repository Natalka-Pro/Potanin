{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NDtmS1YZ8_xc","executionInfo":{"status":"ok","timestamp":1744029431521,"user_tz":-180,"elapsed":36612,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"0f51b433-10e0-4eae-9896-868f292edf95"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd \"drive/MyDrive/Colab Notebooks/mest\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBNBZMU09ENm","executionInfo":{"status":"ok","timestamp":1744029431525,"user_tz":-180,"elapsed":13,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"51469945-5c32-4f2c-964c-9cacfdb10542"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/mest\n"]}]},{"cell_type":"markdown","metadata":{"id":"ub6kk8Oc8-OD"},"source":["# Библиотеки"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"J70SidtE8-OG","executionInfo":{"status":"ok","timestamp":1744029447922,"user_tz":-180,"elapsed":16394,"user":{"displayName":"Наталия","userId":"03780066343814609442"}}},"outputs":[],"source":["import os\n","import pickle\n","from collections import defaultdict\n","\n","import numpy as np\n","import cv2\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","sns.set_theme()\n","\n","import torch\n","\n","from tqdm.notebook import tqdm as tqdm_n\n","from tqdm import tqdm\n","from functools import partial\n","from time import gmtime, strftime, time\n","\n","from torchvision import datasets, models, transforms\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset\n","\n","from torchvision.transforms import v2\n","from torchvision.utils import save_image"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUVEfblq8-OK","executionInfo":{"status":"ok","timestamp":1744029448059,"user_tz":-180,"elapsed":130,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"4254f61a-b321-484f-ddd6-0fc6214be51f"},"outputs":[{"output_type":"stream","name":"stdout","text":["demo.ipynb             \u001b[0m\u001b[01;34mlogs\u001b[0m/          \u001b[01;34mZhukovsky\u001b[0m/  КККМ_bin.zip              \u001b[01;34mКККМfolder9_bin\u001b[0m/\n","kraken_example2.ipynb  Potanin.ipynb  \u001b[01;34mКККМ\u001b[0m/       \u001b[01;34mКККМfolder3_bin\u001b[0m/\n","kraken_example.ipynb   \u001b[01;34mweights\u001b[0m/       \u001b[01;34mКККМ_bin\u001b[0m/   \u001b[01;34mКККМfolder3_strokes_bin\u001b[0m/\n"]}],"source":["ls"]},{"cell_type":"markdown","metadata":{"id":"gUzL-_Hd8-OM"},"source":["# MNIST"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"yQ2Qa8UW8-OO","executionInfo":{"status":"ok","timestamp":1744029448068,"user_tz":-180,"elapsed":6,"user":{"displayName":"Наталия","userId":"03780066343814609442"}}},"outputs":[],"source":["# !pip install kagglehub"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"AxzKXrDW8-OR","executionInfo":{"status":"ok","timestamp":1744029448107,"user_tz":-180,"elapsed":36,"user":{"displayName":"Наталия","userId":"03780066343814609442"}}},"outputs":[],"source":["# import kagglehub\n","\n","# # Download latest version\n","# path = kagglehub.dataset_download(\"hojjatk/mnist-dataset\")\n","\n","# print(\"Path to dataset files:\", path)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"TZD5xQt98-OV","executionInfo":{"status":"ok","timestamp":1744029448118,"user_tz":-180,"elapsed":12,"user":{"displayName":"Наталия","userId":"03780066343814609442"}}},"outputs":[],"source":["# !ls /home/natalkaser/.cache/kagglehub/datasets/hojjatk/mnist-dataset/versions/1"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"KK_8ySX-8-OY","executionInfo":{"status":"ok","timestamp":1744029448126,"user_tz":-180,"elapsed":3,"user":{"displayName":"Наталия","userId":"03780066343814609442"}}},"outputs":[],"source":["# !mv \"{path}\" ."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"n_1UoOJp8-Oa","executionInfo":{"status":"ok","timestamp":1744029448135,"user_tz":-180,"elapsed":5,"user":{"displayName":"Наталия","userId":"03780066343814609442"}}},"outputs":[],"source":["#\n","# This is a sample Notebook to demonstrate how to read \"MNIST Dataset\"\n","#\n","import numpy as np # linear algebra\n","import struct\n","from array import array\n","from os.path  import join\n","\n","# #\n","# # MNIST Data Loader Class\n","# #\n","# class MnistDataloader(object):\n","#     def __init__(self, training_images_filepath,training_labels_filepath,\n","#                  test_images_filepath, test_labels_filepath):\n","#         self.training_images_filepath = training_images_filepath\n","#         self.training_labels_filepath = training_labels_filepath\n","#         self.test_images_filepath = test_images_filepath\n","#         self.test_labels_filepath = test_labels_filepath\n","\n","#     def read_images_labels(self, images_filepath, labels_filepath):\n","#         labels = []\n","#         with open(labels_filepath, 'rb') as file:\n","#             magic, size = struct.unpack(\">II\", file.read(8))\n","#             if magic != 2049:\n","#                 raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n","#             labels = array(\"B\", file.read())\n","\n","#         with open(images_filepath, 'rb') as file:\n","#             magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n","#             if magic != 2051:\n","#                 raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n","#             image_data = array(\"B\", file.read())\n","#         images = []\n","#         for i in range(size):\n","#             images.append([0] * rows * cols)\n","#         for i in range(size):\n","#             img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n","#             img = img.reshape(28, 28)\n","#             images[i][:] = img\n","\n","#         return images, labels\n","\n","#     def load_data(self):\n","#         x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n","#         x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n","#         return (x_train, y_train),(x_test, y_test)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"TeXbtc5X8-Od","executionInfo":{"status":"ok","timestamp":1744029448148,"user_tz":-180,"elapsed":7,"user":{"displayName":"Наталия","userId":"03780066343814609442"}}},"outputs":[],"source":["# input_path = '1'\n","# training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n","# training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n","# test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n","# test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n","\n","\n","# mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n","# (x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n","# print(len(x_train), len(x_test))\n","\n","# def dataset2folder(x, y, name):\n","#     !rm -r \"$name\"\n","\n","#     os.makedirs(name, exist_ok=True)\n","\n","#     cls2counter = defaultdict(int)\n","\n","#     for i in range(len(x)):\n","#         image = np.array(x[i])\n","#         cls = y[i]\n","\n","#         os.makedirs(f\"{name}/{cls}\", exist_ok=True)\n","\n","#         new_name = f\"{name}/{cls}/{cls2counter[cls]}.png\"\n","#         if os.path.exists(new_name):\n","#             raise TypeError\n","\n","#         # print(new_name)\n","#         cv2.imwrite(new_name, image)\n","#         cls2counter[cls] += 1\n","\n","#     print(cls2counter)\n","\n","\n","\n","# dataset2folder(x_train, y_train, \"MNIST/train\")\n","# dataset2folder(x_test, y_test, \"MNIST/test\")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"lPcM6_lU8-Oi","executionInfo":{"status":"ok","timestamp":1744029448262,"user_tz":-180,"elapsed":117,"user":{"displayName":"Наталия","userId":"03780066343814609442"}}},"outputs":[],"source":["# !rm -r 1"]},{"cell_type":"markdown","metadata":{"id":"53xpQ2xj8-Ol"},"source":["# My_Dataset"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"mW3y35d78-Om","executionInfo":{"status":"ok","timestamp":1744029448269,"user_tz":-180,"elapsed":4,"user":{"displayName":"Наталия","userId":"03780066343814609442"}}},"outputs":[],"source":["# https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html\n","\n","class My_Dataset(Dataset):\n","    def __init__(self, folder, transform):\n","        super().__init__()\n","\n","        self.folder = folder\n","        self.transform = transform\n","\n","        self.dir_names = sorted(os.listdir(folder)) # [\"000\" , \"001\", ...]\n","        self.num_cls = len(self.dir_names)\n","\n","        self.dir2cls = {dir : i for i, dir in enumerate(self.dir_names)}\n","        self.cls2dir = {cls : dir for dir, cls in self.dir2cls.items()}\n","\n","        self.dataset = [] # список всех путей до изображений\n","        # image_idx = 0\n","\n","        self.cls2paths = defaultdict(list) # по cls получить все изображения класса\n","\n","        for dir in self.dir_names:\n","            dir_path = os.path.join(folder, dir)\n","\n","            for i in sorted(os.listdir(dir_path)):\n","                image_path = os.path.join(dir_path, i)\n","                cls = self.dir2cls[dir]\n","\n","                self.dataset.append((image_path, cls))\n","                self.cls2paths[cls].append(image_path)\n","                # image_idx += 1\n","\n","        self.cls2count = {cls : len(idxs) for cls, idxs in self.cls2paths.items()}\n","        self.dir2count = {self.cls2dir[cls] : count for cls, count in self.cls2count.items()}\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        image_path, cls = self.dataset[idx]\n","\n","        image = Image.open(image_path).convert(\"RGB\")\n","        image = self.transform(image)\n","\n","        return image, cls\n","\n","\n","class My_TripletDataset(My_Dataset):\n","\n","    def __getitem__(self, idx):\n","        anchor_path, cls = self.dataset[idx]\n","        anchor = self.transform(Image.open(anchor_path).convert(\"RGB\"))\n","\n","        positive_path = random.choice(self.cls2paths[cls])\n","        positive = self.transform(Image.open(positive_path).convert(\"RGB\"))\n","\n","        negative_cls = random.choice([i for i in range(self.num_cls) if i != cls])\n","        negative_path = random.choice(self.cls2paths[negative_cls])\n","        negative = self.transform(Image.open(negative_path).convert(\"RGB\"))\n","\n","        return anchor, positive, negative"]},{"cell_type":"markdown","metadata":{"id":"4mV50_vp8-On"},"source":["# Functions"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"EwSpPONR8-Oo","executionInfo":{"status":"ok","timestamp":1744029448274,"user_tz":-180,"elapsed":3,"user":{"displayName":"Наталия","userId":"03780066343814609442"}}},"outputs":[],"source":["def test_pipeline(model, dataset, collate_fn, device, batch_size):\n","\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n","\n","    for batch in loader:\n","        X_batch, y_batch = batch\n","        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","        output = model(X_batch) # torch.Size([BATCH, NUM_CLS])\n","        print(f\"X_batch: {X_batch.shape}\\ny_batch: {y_batch.shape}\\nmodel:   {output.shape}\")\n","        break\n","\n","\n","def create_model(model, num_freeze_layers, num_out_classes):\n","    # замена последнего слоя сети\n","    model.fc = nn.Linear(512, num_out_classes)\n","\n","    # заморозка слоев\n","    for i, layer in enumerate(model.children()):\n","        if i < num_freeze_layers:\n","            for param in layer.parameters():\n","                param.requires_grad = False\n","\n","    return model\n","\n","\n","def save_logs(logs, path):\n","    with open(path, \"wb\") as f:\n","        pickle.dump(logs, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","def load_logs(path):\n","    with open(path, \"rb\") as f:\n","        logs = pickle.load(f)\n","\n","    return logs\n","\n","def write2file(file, text):\n","    with open(file, 'a') as f:\n","        f.write(text + \"\\n\")\n","\n","def my_time():\n","    return strftime(\"%Y-%m-%d %H:%M:%S \", gmtime(time() + 3 * 60 * 60))\n","\n","def my_timediff(start_time):\n","    return strftime(\"%H:%M:%S\", gmtime(time() - start_time))\n","\n","\n","def number_of_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","def ToModel(model, device):\n","    def fun(tensor, model=model, device=device):\n","        return model(tensor[None, :].to(device))[0]\n","    return fun\n","\n","\n","def Min_size(size):\n","    def fun(tensor, size=size):\n","        c, h, w = tensor.shape\n","        new_h = size\n","        new_w = int(w * new_h / h)\n","\n","        res = transforms.Resize((new_h, new_w))(tensor)\n","        return res\n","\n","    return fun\n","\n","\n","def split_dataset(dataset, percent=0.8):\n","    train_size = int(len(dataset) * percent)\n","    val_size = len(dataset) - train_size\n","\n","    train_dataset, test_dataset = torch.utils.data.random_split(\n","        dataset, [train_size, val_size]\n","    )\n","\n","    len_tr, len_test = len(train_dataset), len(test_dataset)\n","    print(f\"split_dataset: Train: {len_tr} Test: {len_test} Total: {len_tr + len_test}\")\n","\n","    return train_dataset, test_dataset\n","\n","\n","# def find_i(logs, i, names):\n","#     # print(logs, i, names)\n","#     args = []\n","#     for name in names:\n","#         args.append(logs[name][i])\n","#     return args\n","\n","\n","# def print_logs(logs):\n","#     ans = \"\"\n","\n","#     for i in range(len(logs[\"time\"])):\n","#         time, epoch, train_loss, val_loss, train_acc, val_acc = find_i(logs, i,\n","#                                                                        [\"time\", \"epoch\", \"train_loss\", \"val_loss\", \"train_acc\", \"val_acc\"])\n","#         ans += (\"%s epoch: %3i, train/val loss = %.5f / %.5f, acc = %.5f / %.5f\" %\n","#                 (time, epoch, train_loss, val_loss, train_acc, val_acc)) + \"\\n\"\n","\n","\n","#     ans += \"\\nMin train loss:\\n\"\n","#     i, train_loss = logs[\"min_train_loss\"][\"arg\"], logs[\"min_train_loss\"][\"value\"]\n","#     time, epoch, val_loss, train_acc, val_acc = find_i(logs, i,\n","#                                                        [\"time\", \"epoch\", \"val_loss\", \"train_acc\", \"val_acc\"])\n","#     ans += (\"%s epoch: %3i, train/val loss = %.5f / %.5f, acc = %.5f / %.5f\" %\n","#             (time, epoch, train_loss, val_loss, train_acc, val_acc)) + \"\\n\"\n","\n","\n","#     ans += \"Min val loss:\\n\"\n","#     i, val_loss = logs[\"min_val_loss\"][\"arg\"], logs[\"min_val_loss\"][\"value\"]\n","#     time, epoch, train_loss, train_acc, val_acc = find_i(logs, i,\n","#                                                          [\"time\", \"epoch\", \"train_loss\", \"train_acc\", \"val_acc\"])\n","#     ans += (\"%s epoch: %3i, train/val loss = %.5f / %.5f, acc = %.5f / %.5f\" %\n","#             (time, epoch, train_loss, val_loss, train_acc, val_acc)) + \"\\n\"\n","\n","\n","#     ans += \"Max train acc:\\n\"\n","#     i, train_acc = logs[\"max_train_acc\"][\"arg\"], logs[\"max_train_acc\"][\"value\"]\n","#     time, epoch, train_loss, val_loss, val_acc = find_i(logs, i,\n","#                                                         [\"time\", \"epoch\", \"train_loss\", \"val_loss\", \"val_acc\"])\n","#     ans += (\"%s epoch: %3i, train/val loss = %.5f / %.5f, acc = %.5f / %.5f\" %\n","#             (time, epoch, train_loss, val_loss, train_acc, val_acc)) + \"\\n\"\n","\n","\n","#     ans += \"Max val acc:\\n\"\n","#     i, val_acc = logs[\"max_val_acc\"][\"arg\"], logs[\"max_val_acc\"][\"value\"]\n","#     time, epoch, train_loss, val_loss, train_acc = find_i(logs, i,\n","#                                                           [\"time\", \"epoch\", \"train_loss\", \"val_loss\", \"train_acc\"])\n","#     ans += (\"%s epoch: %3i, train/val loss = %.5f / %.5f, acc = %.5f / %.5f\" %\n","#             (time, epoch, train_loss, val_loss, train_acc, val_acc)) + \"\\n\"\n","\n","#     return ans"]},{"cell_type":"markdown","metadata":{"id":"ZqRNmZoG8-Op"},"source":["# Trainer"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"VbKTq7_l8-Op","executionInfo":{"status":"ok","timestamp":1744029448373,"user_tz":-180,"elapsed":96,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bcad354c-a331-4443-e17f-f4ef0d85e907"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cpu\n"]}],"source":["DEVICE=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Device: {DEVICE}\")\n","\n","\n","def load_model(model, path):\n","    print(f\"Load: {path}\")\n","    model.load_state_dict(torch.load(path, map_location=DEVICE))\n","\n","\n","def load_best_model(model, dir):\n","    file = \"logs.pickle\"\n","    path = os.path.join(dir, file)\n","\n","    logs = load_logs(path)\n","    argmax_val_acc = logs[\"max_val_acc\"][\"arg\"]\n","    load_model(model, os.path.join(dir, f\"{argmax_val_acc}epoch.pt\"))\n","    return model\n","\n","\n","class Trainer:\n","    def __init__(\n","            self,\n","            model,\n","            optimizer,\n","            criterion,\n","            type,\n","            dir,\n","            name,\n","            device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n","            early_stopping=10,\n","    ):\n","        os.makedirs(dir, exist_ok=True)\n","\n","        self.model = model.to(device)\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","        self.device = device\n","        self.dir = dir\n","        self.name = name\n","        self.stop = early_stopping\n","        self.savedir = dir + \"/\" + my_time() + self.name # название папки для сохранения\n","\n","        if type == \"siam\":\n","            self._train_step = self._train_step_siam\n","            self._eval_step = self._eval_step_siam\n","\n","        if os.path.exists(self.savedir):\n","            raise TypeError(f\"{self.savedir} exists\")\n","\n","        os.makedirs(self.savedir, exist_ok=True)\n","\n","        self._n_epoch = 0\n","\n","        self.logs = {\n","            \"time\":  [],\n","            \"epoch\": [],\n","            \"train_loss\":   [],\n","            \"val_loss\":     [],\n","            \"train_acc\":    [],\n","            \"val_acc\":      [],\n","            \"min_train_loss\":   {\"arg\" : None, \"value\" : float(\"inf\")},\n","            \"min_val_loss\":     {\"arg\" : None, \"value\" : float(\"inf\")},\n","            \"max_train_acc\":    {\"arg\" : None, \"value\" : 0},\n","            \"max_val_acc\":      {\"arg\" : None, \"value\" : 0},\n","        }\n","\n","    def add_log(self, **args): # Добавить в self.logs словарь args\n","        for key in self.logs:\n","            if key not in args:\n","                print(f\"{key} not in {list(args.keys())}\")\n","            else: # key in args\n","                if type(self.logs[key]) is list:\n","                    self.logs[key].append(args[key])\n","                else:\n","\n","                    if key[:3] == \"min\": # loss\n","                        if args[key][\"value\"] < self.logs[key][\"value\"]:\n","                            self.logs[key] = args[key]\n","                    elif key[:3] == \"max\": # acc\n","                        if args[key][\"value\"] > self.logs[key][\"value\"]:\n","                            self.logs[key] = args[key]\n","\n","\n","    def train(self, train_loader, val_loader, n_epochs):\n","\n","        start_time = time()\n","\n","        val_losses = self.logs[\"val_loss\"]\n","        for epoch in tqdm_n(range(n_epochs), disable=False):\n","            train_loss, train_acc = self._train_step(train_loader)\n","            val_loss, val_acc = self._eval_step(val_loader)\n","\n","            cur_time = my_timediff(start_time)\n","            string = (\"%s epoch: %3i, train/val loss = %.5f / %.5f, acc = %.5f / %.5f\" %\n","                    (cur_time, self._n_epoch, train_loss, val_loss, train_acc, val_acc))\n","            print(string)\n","            write2file(f\"{self.savedir}/logs.txt\", string)\n","            args = {\n","                \"time\": cur_time,\n","                \"epoch\": self._n_epoch,\n","                \"train_loss\": train_loss,\n","                \"val_loss\": val_loss,\n","                \"train_acc\": train_acc,\n","                \"val_acc\": val_acc,\n","                \"min_train_loss\":   {\"arg\" : self._n_epoch, \"value\" : train_loss},\n","                \"min_val_loss\":     {\"arg\" : self._n_epoch, \"value\" : val_loss},\n","                \"max_train_acc\":    {\"arg\" : self._n_epoch, \"value\" : train_acc},\n","                \"max_val_acc\":      {\"arg\" : self._n_epoch, \"value\" : val_acc},\n","            }\n","            self.add_log(**args)\n","\n","            torch.save(self.model.state_dict(), f\"{self.savedir}/{epoch}epoch.pt\")\n","            save_logs(self.logs, f\"{self.savedir}/logs.pickle\")\n","\n","            if len(val_losses) > self.stop and min(val_losses[-self.stop:]) > val_losses[-self.stop-1]:\n","                print(\"Val losses doesn`t decrease!\")\n","                write2file(f\"{self.savedir}/logs.txt\", \"Val losses doesn`t decrease!\")\n","\n","            self._n_epoch += 1\n","\n","\n","    def _train_step(self, dataloader):\n","        self.model.train()\n","\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","\n","        for batch in dataloader:\n","\n","            X_batch, y_batch = batch\n","            X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n","\n","            output = self.model(X_batch) # torch.Size([BATCH, NUM_CLS])\n","            loss = self.criterion(output, y_batch)\n","\n","            y_pred = torch.argmax(output, dim=1)\n","            correct += torch.sum(y_pred == y_batch)\n","            total += len(y_batch)\n","\n","            total_loss += loss\n","            loss.backward()\n","            self.optimizer.step()\n","            self.optimizer.zero_grad()\n","\n","        return total_loss.item() / len(dataloader), correct.item() / total * 100\n","\n","\n","    def _eval_step(self, dataloader):\n","        self.model.eval()\n","\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","\n","        with torch.no_grad():\n","            for batch in dataloader:\n","\n","                X_batch, y_batch = batch\n","                X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n","\n","                output = self.model(X_batch)\n","                loss = self.criterion(output, y_batch)\n","\n","                y_pred = torch.argmax(output, dim=1)\n","                correct += torch.sum(y_pred == y_batch)\n","                total += len(y_batch)\n","\n","                total_loss += loss\n","\n","        return total_loss.item() / len(dataloader), correct.item() / total * 100\n","\n","\n","    def _train_step_siam(self, dataloader):\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","\n","        for batch in dataloader:\n","\n","            anchor, positive, negative = [d.to(self.device) for d in batch]\n","            anchor_output = self.model(anchor)\n","            positive_output = self.model(positive)\n","            negative_output = self.model(negative)\n","\n","            loss = self.criterion(anchor_output, positive_output, negative_output)\n","\n","            correct += (\n","                (torch.norm(anchor_output - positive_output, dim=1)\n","                 < torch.norm(anchor_output - negative_output, dim=1)).sum()\n","                 )\n","            total += anchor.size(0)\n","\n","            total_loss += loss\n","\n","            loss.backward()\n","            self.optimizer.step()\n","            self.optimizer.zero_grad()\n","\n","        return total_loss.item() / len(dataloader), correct.item() / total * 100\n","\n","\n","    def _eval_step_siam(self, dataloader):\n","        total_loss = 0\n","        correct = 0\n","        total = 0\n","\n","        with torch.no_grad():\n","            for batch in dataloader:\n","\n","                anchor, positive, negative = [d.to(self.device) for d in batch]\n","                anchor_output = self.model(anchor)\n","                positive_output = self.model(positive)\n","                negative_output = self.model(negative)\n","\n","                loss = self.criterion(anchor_output, positive_output, negative_output)\n","\n","                correct += (\n","                    (torch.norm(anchor_output - positive_output, dim=1)\n","                    < torch.norm(anchor_output - negative_output, dim=1)).sum()\n","                    )\n","                total += anchor.size(0)\n","\n","                total_loss += loss\n","\n","        return total_loss.item() / len(dataloader), correct.item() / total * 100\n"]},{"cell_type":"markdown","metadata":{"id":"wiu1Lbgr8-Oq"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QvtzEeyG8-Or"},"outputs":[],"source":["class Network(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=10, emb_size=78, hid_size=1000, num_layers=1):\n","        super().__init__()\n","        self.CNN = nn.Sequential(\n","                     nn.Conv2d(in_channels=in_channels, out_channels=3, kernel_size=3),\n","                     nn.BatchNorm2d(3),\n","                     nn.ReLU(),\n","                     nn.MaxPool2d(kernel_size=2, stride=(2, 2)),\n","\n","                     nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3),\n","                     nn.BatchNorm2d(5),\n","                     nn.ReLU(),\n","                     nn.MaxPool2d(kernel_size=2, stride=(2, 2)),\n","\n","                     nn.Conv2d(in_channels=5, out_channels=out_channels, kernel_size=3),\n","                     nn.BatchNorm2d(10),\n","                     nn.ReLU(),\n","                     nn.MaxPool2d(kernel_size=2, stride=(2, 2)),\n","                    )\n","\n","        self.linear = nn.Linear(out_channels, 1)\n","\n","        self.classifier = nn.Sequential(nn.Flatten(),\n","                                        nn.Linear(26 * 26, 10))\n","\n","\n","    def forward(self, x):\n","        # x ~ BATCH_SIZE x C x EMB_SIZE x SEQ_LEN\n","        x = self.CNN(x) # BATCH_SIZE x out_channels x EMB_SIZE_new x SEQ_LEN_new\n","        x = x.permute(0, 2, 3, 1) # BATCH_SIZE x EMB_SIZE_new x SEQ_LEN_new x out_channels\n","        x = self.linear(x).squeeze()\n","        # print(x.shape)\n","        x = self.classifier(x)\n","\n","        return x # BATCH_SIZE x HIDDEN_SIZE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5d3NI1E98-Os"},"outputs":[],"source":["class Network_MNIST(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=10, emb_size=78, hid_size=1000, num_layers=1):\n","        super().__init__()\n","        self.CNN = nn.Sequential(\n","                     nn.Conv2d(in_channels=in_channels, out_channels=3, kernel_size=3),\n","                     nn.BatchNorm2d(3),\n","                     nn.ReLU(),\n","                     # nn.MaxPool2d(kernel_size=2, stride=(2, 2)),\n","\n","                     nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3),\n","                     nn.BatchNorm2d(5),\n","                     nn.ReLU(),\n","                     # nn.MaxPool2d(kernel_size=2, stride=(2, 2)),\n","\n","                     nn.Conv2d(in_channels=5, out_channels=out_channels, kernel_size=3),\n","                     nn.BatchNorm2d(10),\n","                     nn.ReLU(),\n","                     # nn.MaxPool2d(kernel_size=2, stride=(2, 2)),\n","                    )\n","\n","        self.linear = nn.Linear(out_channels, 1)\n","\n","        self.classifier = nn.Sequential(nn.Flatten(),\n","                                        nn.Linear(22 * 22, 10))\n","\n","        # self.classifier = nn.Sequential(nn.Flatten(),\n","        #                                 nn.LazyLinear(10))\n","\n","\n","    def forward(self, x):\n","        # x ~ BATCH_SIZE x C x EMB_SIZE x SEQ_LEN\n","        x = self.CNN(x) # BATCH_SIZE x out_channels x EMB_SIZE_new x SEQ_LEN_new\n","        x = x.permute(0, 2, 3, 1) # BATCH_SIZE x EMB_SIZE_new x SEQ_LEN_new x out_channels\n","        x = self.linear(x).squeeze() # BATCH_SIZE x EMB_SIZE_new x SEQ_LEN_new\n","        x = self.classifier(x)\n","\n","        return x # BATCH_SIZE x HIDDEN_SIZE\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QflspS-r8-Os"},"source":["# MNIST"]},{"cell_type":"markdown","metadata":{"id":"PrtDBusc8-Ot"},"source":["## MNIST CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LlYS_Y3u8-Ou","outputId":"6b04d724-9113-46c1-9fd6-0175246001ef","colab":{"base_uri":"https://localhost:8080/","height":376},"executionInfo":{"status":"error","timestamp":1744014398837,"user_tz":-180,"elapsed":126,"user":{"displayName":"Наталия","userId":"03780066343814609442"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cpu\n","Parameters number: 5581\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'MNIST/train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-0cfa72e242bf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMy_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MNIST/train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMy_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MNIST/test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-927cc77c20b9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, folder, transform)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [\"000\" , \"001\", ...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MNIST/train'"]}],"source":["device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Device: {device}\")\n","\n","model = Network_MNIST().to(device)\n","print(f\"Parameters number: {number_of_parameters(model)}\")\n","\n","transform = transforms.ToTensor()\n","\n","train_dataset = My_Dataset(\"MNIST/train\", transform)\n","test_dataset = My_Dataset(\"MNIST/test\", transform)\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","\n","test_pipeline(model, train_dataset, device, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-F5ZI-Hx8-Ow"},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","BATCH_SIZE = 64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","trainer = Trainer(model, optimizer, criterion, device, dir = \"logs\", name = \"cnn_mnist\")\n","\n","trainer.train(train_loader, val_loader, n_epochs = 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XHAYNpM8-Ox"},"outputs":[],"source":["train_dataset, test_dataset = split_dataset(My_Dataset(\"MNIST/test\", transform))\n","train_dataset = test_dataset\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","BATCH_SIZE = 64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","trainer = Trainer(model, optimizer, criterion, device, dir = \"logs\", name = \"cnn_mnist\")\n","\n","trainer.train(train_loader, val_loader, n_epochs = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BaYODUCN8-Oy"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WiEIOd7U8-Oy"},"outputs":[],"source":["device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","os.makedirs(f\"logs\", exist_ok=True)\n","\n","model = Network().to(device)\n","print(number_of_parameters(model))\n","\n","\n","transform = transforms.Compose([\n","    transforms.RandomCrop(300),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    ])\n","\n","dataset = My_Dataset(\"КККМfolder_bin\", transform)\n","print(len(dataset))\n","\n","train_dataset, test_dataset = split_dataset(dataset)\n","\n","BATCH_SIZE = 64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","trainer = Trainer(model, optimizer, criterion, device, \"logs\", \"cnn\")\n","\n","n_epochs = 100\n","trainer.train(train_loader, val_loader, n_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MfxV0D618-O0"},"outputs":[],"source":["i = 0\n","image, cls = dataset[0]\n","image = image.permute(1, 2, 0).numpy()\n","print(image.shape)\n","plt.imshow(image)\n","plt.grid(False)"]},{"cell_type":"markdown","metadata":{"id":"vLsC8xEK8-O1"},"source":["## MNIST LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O72uJDEA8-O2"},"outputs":[],"source":["class Network_MNIST_LSTM(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=10, emb_size=22, hid_size=32, num_layers=1):\n","        super().__init__()\n","        self.CNN = nn.Sequential(\n","                     nn.Conv2d(in_channels=in_channels, out_channels=3, kernel_size=3),\n","                     nn.BatchNorm2d(3),\n","                     nn.ReLU(),\n","                     # nn.MaxPool2d(kernel_size=2, stride=(2, 2)),\n","\n","                     nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3),\n","                     nn.BatchNorm2d(5),\n","                     nn.ReLU(),\n","                     # nn.MaxPool2d(kernel_size=2, stride=(2, 2)),\n","\n","                     nn.Conv2d(in_channels=5, out_channels=out_channels, kernel_size=3),\n","                     nn.BatchNorm2d(10),\n","                     nn.ReLU(),\n","                     # nn.MaxPool2d(kernel_size=2, stride=(2, 2)),\n","                    )\n","\n","        self.linear = nn.Linear(out_channels, 1)\n","\n","        self.LSTM = nn.LSTM(input_size=emb_size, # emb_size зависит от CNN\n","                            hidden_size=hid_size,\n","                            num_layers=num_layers,\n","                            batch_first=True)\n","\n","\n","        self.classifier = nn.Sequential(nn.Linear(hid_size, 10))\n","        # self.classifier = nn.Sequential(nn.Flatten(),\n","        #                                 nn.Linear(22 * 22, 10))\n","\n","        # self.classifier = nn.Sequential(nn.Flatten(),\n","        #                                 nn.LazyLinear(10))\n","\n","\n","    def forward(self, x):\n","        # x ~ BATCH_SIZE x C x EMB_SIZE x SEQ_LEN\n","        x = self.CNN(x) # BATCH_SIZE x out_channels x EMB_SIZE_new x SEQ_LEN_new\n","        x = x.permute(0, 2, 3, 1) # BATCH_SIZE x EMB_SIZE_new x SEQ_LEN_new x out_channels\n","        x = self.linear(x).squeeze() # BATCH_SIZE x EMB_SIZE_new x SEQ_LEN_new\n","        # print(x.shape)\n","\n","        x = x.permute(0, 2, 1) # BATCH_SIZE x SEQ_LEN_new x EMB_SIZE_new\n","        x, _ = self.LSTM(x) # BATCH_SIZE x SEQ_LEN_new x HIDDEN_SIZE\n","\n","        x = x.mean(dim = 1) # BATCH_SIZE x HIDDEN_SIZE\n","        x = self.classifier(x)\n","        # x = self.classifier(x)\n","\n","        return x # BATCH_SIZE x HIDDEN_SIZE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJwv_aon8-O2"},"outputs":[],"source":["device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Device: {device}\")\n","\n","model = Network_MNIST_LSTM().to(device)\n","print(f\"Parameters number: {number_of_parameters(model)}\")\n","\n","transform = transforms.ToTensor()\n","\n","# train_dataset = My_Dataset(\"MNIST/train\", transform)\n","# test_dataset = My_Dataset(\"MNIST/test\", transform)\n","train_dataset, test_dataset = split_dataset(My_Dataset(\"MNIST/test\", transform))\n","train_dataset = test_dataset\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","\n","test_pipeline(model, train_dataset, device, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mk8cRkDF8-O3"},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","BATCH_SIZE = 64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","trainer = Trainer(model, optimizer, criterion, dir = \"logs\", name = \"cnn_mnist\")\n","\n","trainer.train(train_loader, val_loader, n_epochs = 20)"]},{"cell_type":"markdown","metadata":{"id":"LV8yBycX8-O4"},"source":["# Experiments"]},{"cell_type":"code","source":["for i in model.children():\n","    print(number_of_parameters(i))"],"metadata":{"id":"Rjk_t449Vbgh","executionInfo":{"status":"ok","timestamp":1744029453091,"user_tz":-180,"elapsed":16,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"14f5d004-b8de-4717-fc5d-d2a420fdaa89"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["9408\n","128\n","0\n","0\n","147968\n","525568\n","2099712\n","8393728\n","0\n","513000\n"]}]},{"cell_type":"code","source":["number_of_parameters(model)"],"metadata":{"id":"K3uQC_YJWqh-","executionInfo":{"status":"ok","timestamp":1744029453106,"user_tz":-180,"elapsed":14,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c8554032-48a6-4dd8-a03c-b55577639b09"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11689512"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(DEVICE)\n","model"],"metadata":{"id":"EBqWYiBFTEF6","executionInfo":{"status":"ok","timestamp":1744029453072,"user_tz":-180,"elapsed":4321,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d277f41e-5f6d-4fb8-9613-0e9226a4d87c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 49.7MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ThYgIaha8-O4"},"outputs":[],"source":["# def create_model(model, num_non_freeze, num_out_classes, verbose=False):\n","#     # замена последнего слоя сети\n","#     model.fc = nn.Linear(512, num_out_classes)\n","\n","#     num_param = number_of_parameters(model)\n","#     num_freeze = num_param - num_non_freeze\n","\n","#     # заморозка слоев\n","#     cur_freeze = 0\n","#     for i, layer in enumerate(model.children()):\n","#         for param in layer.parameters():\n","#             if param.requires_grad:\n","#                 if cur_freeze >= num_freeze:\n","#                     return model\n","\n","#                 param.requires_grad = False\n","#                 cur_freeze += param.numel()\n","#                 if verbose:\n","#                     print(num_param - cur_freeze)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"T9IIrb1L8-O5","executionInfo":{"status":"ok","timestamp":1744029561276,"user_tz":-180,"elapsed":55458,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"36c6bba6-60c6-4b85-be69-2228a92b8ec0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cpu\n","Parameters number: 65664\n","368\n","split_dataset: Train: 294 Test: 74 Total: 368\n","train dataset: 294, test dataset: 74\n","X_batch: torch.Size([64, 3, 224, 224])\n","y_batch: torch.Size([64])\n","model:   torch.Size([64, 128])\n"]}],"source":["print(f\"Device: {DEVICE}\")\n","\n","model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(DEVICE)\n","emb_dim = 128\n","# num_non_freeze = 513000\n","# model = create_model(model, num_non_freeze, emb_dim).to(DEVICE)\n","model = create_model(model, num_freeze_layers=9, num_out_classes=emb_dim).to(DEVICE)\n","print(f\"Parameters number: {number_of_parameters(model)}\")\n","\n","# transform = transforms.ToTensor()\n","transform = transforms.Compose(\n","    [\n","            transforms.RandomCrop(300),\n","            transforms.CenterCrop(224),\n","            # transforms.RandomPerspective(distortion_scale=0.5, p=0.5, fill=255),\n","            transforms.ToTensor(),\n","    ])\n","\n","dataset = My_Dataset(\"КККМfolder9_bin\", transform)\n","print(len(dataset))\n","train_dataset, test_dataset = split_dataset(dataset)\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","test_pipeline(model, train_dataset, None, DEVICE, batch_size=64)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"VkXIyHeV8-O6","executionInfo":{"status":"ok","timestamp":1744029644211,"user_tz":-180,"elapsed":47096,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"582ae5d2-7c4e-4907-c831-45e79c01c62a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cpu\n","Parameters number: 70665\n","368\n","split_dataset: Train: 294 Test: 74 Total: 368\n","train dataset: 294, test dataset: 74\n","X_batch: torch.Size([64, 128])\n","y_batch: torch.Size([64])\n","model:   torch.Size([64, 9])\n"]}],"source":["device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Device: {device}\")\n","\n","num_classes = 9\n","cl_model = nn.Sequential(nn.Linear(emb_dim, 512), nn.ReLU(), nn.Linear(512, num_classes)).to(device)\n","print(f\"Parameters number: {number_of_parameters(cl_model)}\")\n","\n","# transform = transforms.ToTensor()\n","transform = transforms.Compose(\n","    [\n","            transforms.RandomCrop(300),\n","            transforms.CenterCrop(224),\n","            # transforms.RandomPerspective(distortion_scale=0.5, p=0.5, fill=255),\n","            transforms.ToTensor(),\n","            ToModel(model, device),\n","    ])\n","\n","dataset = My_Dataset(\"КККМfolder9_bin\", transform)\n","print(len(dataset))\n","train_dataset, test_dataset = split_dataset(dataset)\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","test_pipeline(cl_model, train_dataset, None, device, batch_size=64)"]},{"cell_type":"markdown","source":["## 9 class"],"metadata":{"id":"0yAtl_Ktf0HG"}},{"cell_type":"code","source":["print(f\"Device: {DEVICE}\")\n","\n","model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(DEVICE)\n","emb_dim = 1000\n","model = create_model(model, num_freeze_layers=9, num_out_classes=emb_dim).to(DEVICE)\n","print(f\"Parameters number: {number_of_parameters(model)}\")\n","\n","# transform = transforms.ToTensor()\n","transform = transforms.Compose(\n","    [\n","            transforms.RandomCrop(300),\n","            transforms.CenterCrop(224),\n","            # transforms.RandomPerspective(distortion_scale=0.5, p=0.5, fill=255),\n","            transforms.ToTensor(),\n","    ])\n","\n","\n","dataset = My_TripletDataset(\"КККМfolder9_bin\", transform)\n","print(len(dataset))\n","train_dataset, test_dataset = split_dataset(dataset)\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n","criterion = torch.nn.TripletMarginLoss(margin=9, p=2)\n","\n","BATCH_SIZE = 64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","trainer = Trainer(model, optimizer, criterion, type = \"siam\", dir = \"logs\", name = \"siam9\")\n","\n","trainer.train(train_loader, val_loader, n_epochs = 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":674,"referenced_widgets":["e0d2939eb5264e7f9a3f27eec2dd4d3f","49ec89dfb307456b807927de0f33ec5e","e1ac41976b104da08a1cb594d72534ca","b1460c57d9654f0cac9833e797bc0364","d227394f5cc542e9a775f0a32ed1c21f","4aa25146b7764f45a536bbb6063b8708","dae1e57f52cb48749f7466bc8106133d","b1dc23d5b32b49d0990f58b2c8e6922f","ee62a2ff1106476593b737a397f760b1","edca847ed5de450a91c9a88a4fa6d5f5","7cb200ebd2314ea28a6dc4e52a291249"]},"id":"1NbaQwqA-yyL","executionInfo":{"status":"ok","timestamp":1744017796966,"user_tz":-180,"elapsed":321913,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"4da5faf1-fd1b-4ef6-a86c-b7e6f56cb624"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","Parameters number: 513000\n","368\n","split_dataset: Train: 294 Test: 74 Total: 368\n","train dataset: 294, test dataset: 74\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0d2939eb5264e7f9a3f27eec2dd4d3f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["00:00:10 epoch:   0, train/val loss = 8.19792 / 7.78778, acc = 67.00680 / 60.81081\n","00:00:21 epoch:   1, train/val loss = 7.72383 / 7.69966, acc = 69.72789 / 63.51351\n","00:00:32 epoch:   2, train/val loss = 7.81807 / 7.42818, acc = 65.30612 / 62.16216\n","00:00:43 epoch:   3, train/val loss = 7.44752 / 7.42285, acc = 65.64626 / 68.91892\n","00:00:54 epoch:   4, train/val loss = 7.50978 / 6.75309, acc = 67.00680 / 68.91892\n","00:01:05 epoch:   5, train/val loss = 7.30359 / 7.29879, acc = 61.56463 / 70.27027\n","00:01:15 epoch:   6, train/val loss = 6.44201 / 6.37488, acc = 72.44898 / 72.97297\n","00:01:26 epoch:   7, train/val loss = 7.33190 / 8.14032, acc = 65.64626 / 64.86486\n","00:01:37 epoch:   8, train/val loss = 6.54526 / 5.37592, acc = 69.72789 / 71.62162\n","00:01:47 epoch:   9, train/val loss = 6.68367 / 6.53868, acc = 70.40816 / 71.62162\n","00:01:58 epoch:  10, train/val loss = 6.70930 / 5.83434, acc = 68.36735 / 70.27027\n","00:02:09 epoch:  11, train/val loss = 6.51460 / 6.45848, acc = 73.12925 / 68.91892\n","00:02:19 epoch:  12, train/val loss = 6.96972 / 5.72339, acc = 66.32653 / 74.32432\n","00:02:30 epoch:  13, train/val loss = 6.28944 / 6.67580, acc = 72.10884 / 66.21622\n","00:02:41 epoch:  14, train/val loss = 5.85679 / 6.36955, acc = 74.48980 / 66.21622\n","00:02:52 epoch:  15, train/val loss = 5.87613 / 6.01247, acc = 71.76871 / 66.21622\n","00:03:02 epoch:  16, train/val loss = 6.32202 / 5.54089, acc = 69.38776 / 71.62162\n","00:03:13 epoch:  17, train/val loss = 5.74430 / 4.74014, acc = 74.48980 / 77.02703\n","00:03:23 epoch:  18, train/val loss = 6.00768 / 6.78654, acc = 71.08844 / 59.45946\n","00:03:34 epoch:  19, train/val loss = 5.86108 / 5.06291, acc = 76.19048 / 75.67568\n","00:03:45 epoch:  20, train/val loss = 5.66745 / 4.15668, acc = 73.12925 / 79.72973\n","00:03:56 epoch:  21, train/val loss = 5.79301 / 5.24031, acc = 72.44898 / 74.32432\n","00:04:06 epoch:  22, train/val loss = 5.41617 / 4.60485, acc = 77.55102 / 70.27027\n","00:04:16 epoch:  23, train/val loss = 6.27338 / 7.65331, acc = 70.74830 / 74.32432\n","00:04:27 epoch:  24, train/val loss = 5.95456 / 5.67567, acc = 72.78912 / 66.21622\n","00:04:38 epoch:  25, train/val loss = 5.74309 / 4.96919, acc = 74.14966 / 78.37838\n","00:04:49 epoch:  26, train/val loss = 5.58634 / 5.50156, acc = 73.80952 / 79.72973\n","00:05:00 epoch:  27, train/val loss = 5.63248 / 4.63747, acc = 74.82993 / 78.37838\n","00:05:10 epoch:  28, train/val loss = 5.05743 / 5.06985, acc = 80.61224 / 74.32432\n","00:05:21 epoch:  29, train/val loss = 5.30690 / 4.16853, acc = 76.19048 / 83.78378\n"]}]},{"cell_type":"code","source":["model = load_best_model(model, dir=\"logs/2025-04-07 12:17:55 siam9\")\n","eval_siam(model, train_loader), eval_siam(model, val_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Va0K5xn-gI73","executionInfo":{"status":"ok","timestamp":1744017807902,"user_tz":-180,"elapsed":10901,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"cf1c5e85-a822-454c-9b0b-e053eb6ff2b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Load: logs/2025-04-07 12:17:55 siam9/29epoch.pt\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor(75.1701, device='cuda:0'), tensor(74.3243, device='cuda:0'))"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["### classification 9"],"metadata":{"id":"jAnNMzwzgVEd"}},{"cell_type":"code","source":["num_classes = 9\n","cl_model = nn.Sequential(nn.Linear(emb_dim, 512), nn.ReLU(), nn.Linear(512, num_classes)).to(DEVICE)\n","print(f\"Parameters number: {number_of_parameters(cl_model)}\")\n","\n","model.eval()\n","for p in model.parameters():\n","    p.requires_grad = False\n","print(f\"Parameters number: {number_of_parameters(model)}\")\n","\n","# transform = transforms.ToTensor()\n","transform = transforms.Compose(\n","    [\n","            transforms.RandomCrop(300),\n","            transforms.CenterCrop(224),\n","            # transforms.RandomPerspective(distortion_scale=0.5, p=0.5, fill=255),\n","            transforms.ToTensor(),\n","            ToModel(model, DEVICE),\n","    ])\n","\n","dataset = My_Dataset(\"КККМfolder9_bin\", transform)\n","print(len(dataset))\n","train_dataset, test_dataset = split_dataset(dataset)\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","optimizer = torch.optim.Adam(cl_model.parameters(), lr=3e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","BATCH_SIZE = 64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","trainer = Trainer(cl_model, optimizer, criterion, type = \"not siam\", dir = \"logs\", name = \"cl9\")\n","\n","trainer.train(train_loader, val_loader, n_epochs = 20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496,"referenced_widgets":["7bcd134bc68d4729a9ee226424bc8486","5a9cb8b87c1141798b434de4605ccd62","3390b8bfcd4d430ea0911cbfa196993e","1f3d91a549ce48329e0fefb86a29aed4","54b1d618a2fa455fad0fdab20e2d6fa9","bfa17ad8ab824af0b14aa2a2f330a1bd","6e4e72b0b9dd411982e9b37e68996ca8","428a765e25f74788a535e7961a281e05","3af4320e852742dfbd70472121f0cf89","30de8e939f8d420293c45b6b56b43010","9a781d596ac142c192e4b31968d768d1"]},"id":"5xM32Au0-y39","executionInfo":{"status":"ok","timestamp":1744018132577,"user_tz":-180,"elapsed":88474,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"66565759-0639-4066-e5a0-208f77c34c9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameters number: 517129\n","Parameters number: 0\n","368\n","split_dataset: Train: 294 Test: 74 Total: 368\n","train dataset: 294, test dataset: 74\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bcd134bc68d4729a9ee226424bc8486"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["00:00:04 epoch:   0, train/val loss = 1.90687 / 1.70913, acc = 28.57143 / 54.05405\n","00:00:08 epoch:   1, train/val loss = 1.53090 / 1.51438, acc = 48.29932 / 58.10811\n","00:00:13 epoch:   2, train/val loss = 1.31568 / 1.31548, acc = 56.80272 / 68.91892\n","00:00:17 epoch:   3, train/val loss = 1.22433 / 1.24236, acc = 58.84354 / 67.56757\n","00:00:22 epoch:   4, train/val loss = 1.18139 / 1.28852, acc = 62.58503 / 62.16216\n","00:00:26 epoch:   5, train/val loss = 1.07421 / 0.96348, acc = 64.96599 / 64.86486\n","00:00:30 epoch:   6, train/val loss = 1.08892 / 1.11722, acc = 62.92517 / 72.97297\n","00:00:35 epoch:   7, train/val loss = 1.08839 / 1.16443, acc = 64.62585 / 66.21622\n","00:00:39 epoch:   8, train/val loss = 1.00812 / 0.97733, acc = 62.92517 / 70.27027\n","00:00:43 epoch:   9, train/val loss = 0.99196 / 1.27993, acc = 64.62585 / 64.86486\n","00:00:48 epoch:  10, train/val loss = 0.97478 / 0.78424, acc = 67.34694 / 82.43243\n","00:00:53 epoch:  11, train/val loss = 0.98060 / 1.23392, acc = 64.28571 / 63.51351\n","00:00:57 epoch:  12, train/val loss = 1.01975 / 0.96867, acc = 63.94558 / 74.32432\n","00:01:02 epoch:  13, train/val loss = 0.96153 / 0.89950, acc = 62.92517 / 68.91892\n","00:01:06 epoch:  14, train/val loss = 0.95920 / 0.89390, acc = 64.96599 / 72.97297\n","00:01:10 epoch:  15, train/val loss = 0.94024 / 0.89959, acc = 64.28571 / 67.56757\n","00:01:15 epoch:  16, train/val loss = 0.90274 / 0.92156, acc = 64.28571 / 71.62162\n","00:01:19 epoch:  17, train/val loss = 0.90577 / 0.98717, acc = 70.06803 / 68.91892\n","00:01:23 epoch:  18, train/val loss = 0.90270 / 1.13525, acc = 66.66667 / 74.32432\n","00:01:28 epoch:  19, train/val loss = 0.90545 / 0.97392, acc = 70.06803 / 71.62162\n"]}]},{"cell_type":"code","source":["cl_model = load_best_model(cl_model, dir=\"logs/2025-04-07 12:27:23 cl9\")\n","eval(cl_model, train_loader)[-1], eval(cl_model, val_loader)[-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYXmTqDxlE8Y","executionInfo":{"status":"ok","timestamp":1744018396533,"user_tz":-180,"elapsed":4934,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"b1bb4e14-7c2d-401a-a44a-e75c0081b6b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Load: logs/2025-04-07 12:27:23 cl9/10epoch.pt\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor(68.0272, device='cuda:0'), tensor(70.2703, device='cuda:0'))"]},"metadata":{},"execution_count":69}]},{"cell_type":"markdown","source":["## 3 class"],"metadata":{"id":"EM1DVMnfXIwm"}},{"cell_type":"code","source":["print(f\"Device: {DEVICE}\")\n","\n","model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(DEVICE)\n","emb_dim = 1000\n","model = create_model(model, num_freeze_layers=9, num_out_classes=emb_dim).to(DEVICE)\n","print(f\"Parameters number: {number_of_parameters(model)}\")\n","\n","# transform = transforms.ToTensor()\n","transform = transforms.Compose(\n","    [\n","            transforms.RandomCrop(300),\n","            transforms.CenterCrop(224),\n","            # transforms.RandomPerspective(distortion_scale=0.5, p=0.5, fill=255),\n","            transforms.ToTensor(),\n","    ])\n","\n","\n","dataset = My_TripletDataset(\"КККМfolder3_bin\", transform)\n","print(len(dataset))\n","train_dataset, test_dataset = split_dataset(dataset)\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n","criterion = torch.nn.TripletMarginLoss(margin=9, p=2)\n","\n","BATCH_SIZE = 64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","trainer = Trainer(model, optimizer, criterion, type = \"siam\", dir = \"logs\", name = \"siam3\")\n","\n","trainer.train(train_loader, val_loader, n_epochs = 30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":674,"referenced_widgets":["a54ce8492ede4436b6da22f462e26926","a671a821b48f4bf29c36f3234e75499a","c4c13f039d1e4bac98512e5fa5c0d348","93edf958eb8f45a4aecb598e5e02976a","1968c0f8deca4ccc9e637f2ec786e12c","a9e74f52d846484fba7f6a595fc891da","5f155a8226b2459f8c160ccb0230b4f4","b0062c8b87314b8793f30c8ef32171ee","db43fc4045cb489ebe723786695cd30b","e4668cd71ef44df8a22c13e26c7f247c","7738aa829a49445c9ecbe6284aaa6a4e"]},"id":"eqLKted6A1sp","executionInfo":{"status":"ok","timestamp":1744015489024,"user_tz":-180,"elapsed":179524,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"d62ad1c0-3d17-44c8-89bb-8b2be311f4c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","Parameters number: 513000\n","169\n","split_dataset: Train: 135 Test: 34 Total: 169\n","train dataset: 135, test dataset: 34\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a54ce8492ede4436b6da22f462e26926"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["00:00:06 epoch:   0, train/val loss = 7.38875 / 7.54014, acc = 66.66667 / 64.70588\n","00:00:10 epoch:   1, train/val loss = 7.37967 / 7.27768, acc = 70.37037 / 73.52941\n","00:00:21 epoch:   2, train/val loss = 6.26643 / 6.98284, acc = 71.11111 / 70.58824\n","00:00:27 epoch:   3, train/val loss = 6.72455 / 6.76764, acc = 73.33333 / 79.41176\n","00:00:32 epoch:   4, train/val loss = 6.22665 / 5.98606, acc = 75.55556 / 79.41176\n","00:00:38 epoch:   5, train/val loss = 7.24285 / 6.24401, acc = 71.11111 / 73.52941\n","00:00:44 epoch:   6, train/val loss = 5.67856 / 6.28494, acc = 78.51852 / 67.64706\n","00:00:53 epoch:   7, train/val loss = 4.91405 / 6.62445, acc = 77.77778 / 67.64706\n","00:00:59 epoch:   8, train/val loss = 4.92058 / 6.49648, acc = 78.51852 / 73.52941\n","00:01:04 epoch:   9, train/val loss = 4.53222 / 5.65807, acc = 78.51852 / 64.70588\n","00:01:09 epoch:  10, train/val loss = 4.24866 / 6.29330, acc = 79.25926 / 64.70588\n","00:01:15 epoch:  11, train/val loss = 3.96867 / 5.46336, acc = 83.70370 / 88.23529\n","00:01:19 epoch:  12, train/val loss = 4.91660 / 6.91543, acc = 80.00000 / 67.64706\n","00:01:26 epoch:  13, train/val loss = 4.94542 / 5.00781, acc = 80.00000 / 67.64706\n","00:01:33 epoch:  14, train/val loss = 5.21233 / 7.34973, acc = 76.29630 / 70.58824\n","00:01:42 epoch:  15, train/val loss = 5.23936 / 5.46477, acc = 81.48148 / 76.47059\n","00:01:47 epoch:  16, train/val loss = 3.92773 / 5.77738, acc = 81.48148 / 79.41176\n","00:01:53 epoch:  17, train/val loss = 5.43688 / 5.54326, acc = 78.51852 / 76.47059\n","00:01:58 epoch:  18, train/val loss = 6.14610 / 4.95933, acc = 73.33333 / 79.41176\n","00:02:03 epoch:  19, train/val loss = 5.34905 / 3.92403, acc = 75.55556 / 82.35294\n","00:02:09 epoch:  20, train/val loss = 4.20483 / 6.01301, acc = 77.77778 / 70.58824\n","00:02:14 epoch:  21, train/val loss = 5.28155 / 5.27201, acc = 81.48148 / 76.47059\n","00:02:20 epoch:  22, train/val loss = 4.57857 / 5.14874, acc = 77.03704 / 76.47059\n","00:02:25 epoch:  23, train/val loss = 5.81319 / 6.70753, acc = 78.51852 / 70.58824\n","00:02:31 epoch:  24, train/val loss = 5.38421 / 3.81398, acc = 74.07407 / 85.29412\n","00:02:36 epoch:  25, train/val loss = 5.50112 / 5.01403, acc = 80.74074 / 70.58824\n","00:02:41 epoch:  26, train/val loss = 3.89716 / 4.95198, acc = 82.22222 / 73.52941\n","00:02:47 epoch:  27, train/val loss = 3.60177 / 6.65254, acc = 80.00000 / 67.64706\n","00:02:52 epoch:  28, train/val loss = 3.40071 / 6.13510, acc = 79.25926 / 70.58824\n","00:02:58 epoch:  29, train/val loss = 5.05750 / 4.59040, acc = 78.51852 / 79.41176\n"]}]},{"cell_type":"code","source":["def eval_siam(model, dataloader):\n","    total_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    ans = []\n","    true = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","\n","            anchor, positive, negative = [d.to(DEVICE) for d in batch]\n","            anchor_output = model(anchor)\n","            positive_output = model(positive)\n","            negative_output = model(negative)\n","\n","            correct += (\n","                (torch.norm(anchor_output - positive_output, dim=1)\n","                < torch.norm(anchor_output - negative_output, dim=1)).sum()\n","                )\n","            total += anchor.size(0)\n","\n","    return correct / total * 100"],"metadata":{"id":"nllQ4uVDdWfq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = load_best_model(model, dir=\"logs/2025-04-07 11:41:49 siam3\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOaCWZ3xcTIP","executionInfo":{"status":"ok","timestamp":1744016367315,"user_tz":-180,"elapsed":117,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"8341ad7b-cace-497a-9c0a-8af33c90202a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Load: logs/2025-04-07 11:41:49 siam3/11epoch.pt\n"]}]},{"cell_type":"code","source":["eval_siam(model, train_loader), eval_siam(model, val_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HChxWJyddR9I","executionInfo":{"status":"ok","timestamp":1744016401927,"user_tz":-180,"elapsed":5165,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"1eb35bed-8136-4cfb-9d55-7833caf8138c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(80.7407, device='cuda:0'), tensor(79.4118, device='cuda:0'))"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# test_pipeline(model, My_Dataset(\"КККМfolder3_bin\", transform), DEVICE, batch_size=64)"],"metadata":{"id":"iWYSEN2mYPv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HHZ1_K6caoa9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### classification 3"],"metadata":{"id":"inzwdzO8gahw"}},{"cell_type":"code","source":["num_classes = 3\n","cl_model = nn.Sequential(nn.Linear(emb_dim, 512), nn.ReLU(), nn.Linear(512, num_classes)).to(DEVICE)\n","print(f\"Parameters number: {number_of_parameters(cl_model)}\")\n","\n","model.eval()\n","for p in model.parameters():\n","    p.requires_grad = False\n","print(f\"Parameters number: {number_of_parameters(model)}\")\n","\n","# transform = transforms.ToTensor()\n","transform = transforms.Compose(\n","    [\n","            transforms.RandomCrop(300),\n","            transforms.CenterCrop(224),\n","            # transforms.RandomPerspective(distortion_scale=0.5, p=0.5, fill=255),\n","            transforms.ToTensor(),\n","            ToModel(model, DEVICE),\n","    ])\n","\n","dataset = My_Dataset(\"КККМfolder3_bin\", transform)\n","print(len(dataset))\n","train_dataset, test_dataset = split_dataset(dataset)\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","optimizer = torch.optim.Adam(cl_model.parameters(), lr=3e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","BATCH_SIZE = 64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","trainer = Trainer(cl_model, optimizer, criterion, type = \"not siam\", dir = \"logs\", name = \"cl3\")\n","\n","trainer.train(train_loader, val_loader, n_epochs = 20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496,"referenced_widgets":["70b4c0286c8e473380180ac0c8907149","f7800e95fbc147d7aa48f8d31c28ee00","9ce10aab4f954c9391e25e806f226d7e","76e689ca4afe41fca51bda02fdaa5ac8","987dd545dc174c06b719c4adbec75a53","37f56d1153054aceb575d2c12ed26d79","fc954db258b3488eb60dd8776659b3a7","135e17457f16455398e487fa958f6945","ff71b597b95543bd98a14f2eaef8e5de","2e6451b07ff242fb89fefc3769246287","904446c2111940a9bf093d4b5f2eb959"]},"id":"-HlWNNauBbQW","executionInfo":{"status":"ok","timestamp":1744016551125,"user_tz":-180,"elapsed":41405,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"e69fac1d-43a8-4316-ae00-d5890e42cb2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameters number: 514051\n","Parameters number: 0\n","169\n","split_dataset: Train: 135 Test: 34 Total: 169\n","train dataset: 135, test dataset: 34\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70b4c0286c8e473380180ac0c8907149"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["00:00:01 epoch:   0, train/val loss = 0.95181 / 0.77885, acc = 46.66667 / 70.58824\n","00:00:03 epoch:   1, train/val loss = 0.79588 / 0.61123, acc = 65.92593 / 76.47059\n","00:00:05 epoch:   2, train/val loss = 0.66653 / 0.51228, acc = 77.03704 / 85.29412\n","00:00:07 epoch:   3, train/val loss = 0.51065 / 0.57240, acc = 78.51852 / 76.47059\n","00:00:09 epoch:   4, train/val loss = 0.55873 / 0.40233, acc = 80.00000 / 82.35294\n","00:00:12 epoch:   5, train/val loss = 0.51810 / 0.42855, acc = 76.29630 / 85.29412\n","00:00:14 epoch:   6, train/val loss = 0.47841 / 0.45193, acc = 83.70370 / 85.29412\n","00:00:16 epoch:   7, train/val loss = 0.45151 / 0.35936, acc = 80.74074 / 85.29412\n","00:00:18 epoch:   8, train/val loss = 0.48672 / 0.50801, acc = 82.22222 / 79.41176\n","00:00:19 epoch:   9, train/val loss = 0.57560 / 0.40308, acc = 80.74074 / 85.29412\n","00:00:21 epoch:  10, train/val loss = 0.47179 / 0.32575, acc = 83.70370 / 85.29412\n","00:00:24 epoch:  11, train/val loss = 0.36687 / 0.32484, acc = 83.70370 / 94.11765\n","00:00:26 epoch:  12, train/val loss = 0.37576 / 0.37253, acc = 82.96296 / 88.23529\n","00:00:28 epoch:  13, train/val loss = 0.35067 / 0.36545, acc = 85.18519 / 88.23529\n","00:00:30 epoch:  14, train/val loss = 0.31735 / 0.33497, acc = 87.40741 / 88.23529\n","00:00:32 epoch:  15, train/val loss = 0.43404 / 0.42277, acc = 85.18519 / 85.29412\n","00:00:34 epoch:  16, train/val loss = 0.67501 / 0.29226, acc = 88.14815 / 88.23529\n","00:00:37 epoch:  17, train/val loss = 0.43199 / 0.37381, acc = 83.70370 / 91.17647\n","00:00:39 epoch:  18, train/val loss = 0.40317 / 0.38475, acc = 81.48148 / 76.47059\n","00:00:41 epoch:  19, train/val loss = 0.27657 / 0.35429, acc = 88.88889 / 85.29412\n"]}]},{"cell_type":"code","source":["def eval(model, dataloader):\n","    correct = 0\n","    total = 0\n","\n","    ans = []\n","    true = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","\n","            X_batch, y_batch = batch\n","            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n","\n","            output = model(X_batch)\n","            y_pred = torch.argmax(output, dim=1)\n","            ans.append(y_pred)\n","            true.append(y_batch)\n","\n","            correct += torch.sum(y_pred == y_batch)\n","            total += len(y_batch)\n","\n","    ans = torch.cat(ans)\n","    true = torch.cat(true)\n","\n","    return ans, true, correct / total * 100"],"metadata":{"id":"Yvfxdir7CmEx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans, true, acc = eval(cl_model, train_loader)\n","ans, true, acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sH9arPn-fIXL","executionInfo":{"status":"ok","timestamp":1744016687150,"user_tz":-180,"elapsed":1490,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"f2184b20-fcd4-4b76-dd8f-793850941641"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 2, 0,\n","         0, 2, 1, 1, 2, 0, 0, 1, 2, 2, 1, 0, 2, 2, 0, 2, 1, 0, 1, 0, 1, 2, 1, 2,\n","         0, 1, 2, 2, 2, 1, 0, 1, 2, 2, 1, 1, 0, 2, 2, 2, 1, 2, 1, 2, 0, 2, 1, 0,\n","         1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 0, 0, 1, 2, 1, 2, 1, 1,\n","         2, 2, 1, 2, 1, 2, 2, 2, 0, 1, 2, 1, 2, 2, 2, 1, 2, 2, 0, 2, 1, 1, 2, 2,\n","         1, 1, 1, 2, 2, 0, 2, 1, 2, 1, 0, 2, 2, 1, 2], device='cuda:0'),\n"," tensor([2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 1, 1, 0, 2, 1, 0, 0, 2, 1, 0, 1,\n","         0, 2, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 2, 2, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1,\n","         0, 1, 2, 1, 2, 1, 0, 1, 1, 0, 1, 1, 0, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 0,\n","         1, 2, 0, 1, 1, 2, 1, 2, 1, 1, 2, 0, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 1, 1,\n","         2, 1, 1, 2, 2, 1, 2, 2, 0, 1, 2, 1, 2, 0, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2,\n","         1, 1, 0, 2, 2, 0, 2, 1, 2, 1, 0, 0, 2, 1, 2], device='cuda:0'),\n"," tensor(82.2222, device='cuda:0'))"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":[],"metadata":{"id":"qaYtlxiBLQRU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ljjakjtgLQVK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# old"],"metadata":{"id":"r15GZLSmmSpr"}},{"cell_type":"code","source":["device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Device: {device}\")\n","\n","model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(device)\n","emb_dim = 1000\n","num_non_freeze = 513000\n","model = create_model(model, num_non_freeze, emb_dim).to(device)\n","print(f\"Parameters number: {number_of_parameters(model)}\")\n","\n","\n","transform = transforms.Compose(\n","    [\n","            transforms.RandomCrop(300),\n","            transforms.CenterCrop(224),\n","            # transforms.RandomPerspective(distortion_scale=0.5, p=0.5, fill=255),\n","            transforms.ToTensor(),\n","    ])\n","\n","dataset = My_TripletDataset(\"КККМfolder10_bin\", transform)\n","print(len(dataset))\n","train_dataset, test_dataset = split_dataset(dataset)\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n","criterion = torch.nn.TripletMarginLoss(margin=9, p=2)\n","\n","BATCH_SIZE = 64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","trainer = Trainer(model, optimizer, criterion, type = \"siam\", dir = \"logs\", name = \"cnn_mnist\")\n","\n","trainer.train(train_loader, val_loader, n_epochs = 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8c4862c8d0594a7c988f3d593934c71b","fafe60b71e50487bba675f51b3657ebd","c25f73a9ca3846c59893c9af088e9541","be518a0b8d6f4d5698082fc99eae1e02","4652dbda94f946339eb3f07b582eff54","b8e8ca5734524db7a1194cdf617393d3","621e2bc91657468492828d975c45e135","40ac9804a9d1490b88382b8041979768","251c8586be294ae9a36ba14f99cbfa92","93faf19a9bd5428683e6518756fb6c4d","e0c5d7a585184d1e9fff9b2817e8cb32"]},"id":"jgQA93gELQZw","executionInfo":{"status":"ok","timestamp":1743425351616,"user_tz":-180,"elapsed":1138290,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"181ee6fa-67be-4165-8afc-cca25bc0d121"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","Parameters number: 513000\n","368\n","split_dataset: Train: 294 Test: 74 Total: 368\n","train dataset: 294, test dataset: 74\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c4862c8d0594a7c988f3d593934c71b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["00:00:11 epoch:   0, train/val loss = 8.23671 / 8.52085, acc = 60.54422 / 55.40541\n","00:00:22 epoch:   1, train/val loss = 7.96706 / 7.57170, acc = 64.96599 / 71.62162\n","00:00:34 epoch:   2, train/val loss = 7.71006 / 8.52990, acc = 63.94558 / 59.45946\n","00:00:45 epoch:   3, train/val loss = 7.44238 / 8.03850, acc = 67.00680 / 67.56757\n","00:00:56 epoch:   4, train/val loss = 7.29708 / 6.84651, acc = 68.02721 / 71.62162\n","00:01:08 epoch:   5, train/val loss = 6.77435 / 6.41460, acc = 69.38776 / 77.02703\n","00:01:20 epoch:   6, train/val loss = 6.80362 / 6.00551, acc = 66.66667 / 71.62162\n","00:01:31 epoch:   7, train/val loss = 6.93195 / 4.40005, acc = 68.02721 / 79.72973\n","00:01:43 epoch:   8, train/val loss = 6.72442 / 5.67524, acc = 67.68707 / 70.27027\n","00:01:54 epoch:   9, train/val loss = 6.81776 / 6.91615, acc = 66.32653 / 64.86486\n","00:02:06 epoch:  10, train/val loss = 6.47240 / 6.53407, acc = 70.74830 / 70.27027\n","00:02:17 epoch:  11, train/val loss = 5.83814 / 7.06862, acc = 72.78912 / 67.56757\n","00:02:28 epoch:  12, train/val loss = 6.86432 / 6.70512, acc = 68.36735 / 62.16216\n","00:02:39 epoch:  13, train/val loss = 6.36692 / 5.02454, acc = 72.44898 / 78.37838\n","00:02:51 epoch:  14, train/val loss = 6.23187 / 6.07908, acc = 73.80952 / 75.67568\n","00:03:03 epoch:  15, train/val loss = 6.03974 / 6.43574, acc = 70.74830 / 63.51351\n","00:03:14 epoch:  16, train/val loss = 5.80948 / 5.74077, acc = 74.48980 / 70.27027\n","00:03:25 epoch:  17, train/val loss = 6.06259 / 4.88968, acc = 75.51020 / 75.67568\n","Val losses doesn`t decrease!\n","00:03:36 epoch:  18, train/val loss = 5.71281 / 6.26379, acc = 75.51020 / 81.08108\n","00:03:48 epoch:  19, train/val loss = 5.91257 / 6.18488, acc = 74.48980 / 70.27027\n","00:03:59 epoch:  20, train/val loss = 6.03410 / 4.58701, acc = 72.44898 / 78.37838\n","00:04:11 epoch:  21, train/val loss = 5.64290 / 8.63282, acc = 72.78912 / 63.51351\n","00:04:22 epoch:  22, train/val loss = 5.43316 / 4.98660, acc = 73.12925 / 75.67568\n","00:04:34 epoch:  23, train/val loss = 5.41356 / 6.39866, acc = 77.21088 / 75.67568\n","00:04:45 epoch:  24, train/val loss = 6.05713 / 5.71573, acc = 72.10884 / 72.97297\n","00:04:56 epoch:  25, train/val loss = 5.24092 / 4.58464, acc = 75.51020 / 70.27027\n","00:05:08 epoch:  26, train/val loss = 5.91577 / 6.54209, acc = 72.10884 / 78.37838\n","00:05:19 epoch:  27, train/val loss = 5.47859 / 6.27996, acc = 75.85034 / 78.37838\n","00:05:31 epoch:  28, train/val loss = 5.59036 / 4.26296, acc = 74.48980 / 78.37838\n","00:05:42 epoch:  29, train/val loss = 6.03939 / 6.00530, acc = 70.74830 / 71.62162\n","00:05:54 epoch:  30, train/val loss = 4.40749 / 5.89275, acc = 83.67347 / 68.91892\n","00:06:05 epoch:  31, train/val loss = 5.25197 / 4.86551, acc = 76.87075 / 71.62162\n","00:06:16 epoch:  32, train/val loss = 5.35030 / 7.15195, acc = 77.55102 / 74.32432\n","00:06:28 epoch:  33, train/val loss = 5.31006 / 5.45484, acc = 79.25170 / 74.32432\n","00:06:39 epoch:  34, train/val loss = 5.42289 / 5.16223, acc = 74.82993 / 70.27027\n","00:06:51 epoch:  35, train/val loss = 5.18790 / 4.68189, acc = 74.82993 / 81.08108\n","00:07:02 epoch:  36, train/val loss = 5.00425 / 5.19931, acc = 77.55102 / 75.67568\n","00:07:14 epoch:  37, train/val loss = 5.40785 / 6.24482, acc = 73.46939 / 67.56757\n","00:07:25 epoch:  38, train/val loss = 5.25252 / 4.77038, acc = 75.51020 / 82.43243\n","Val losses doesn`t decrease!\n","00:07:36 epoch:  39, train/val loss = 4.69913 / 5.96366, acc = 79.93197 / 75.67568\n","00:07:47 epoch:  40, train/val loss = 5.32452 / 5.01944, acc = 71.42857 / 85.13514\n","00:07:59 epoch:  41, train/val loss = 4.72144 / 5.64254, acc = 78.23129 / 78.37838\n","00:08:10 epoch:  42, train/val loss = 5.42756 / 5.23269, acc = 76.87075 / 74.32432\n","00:08:22 epoch:  43, train/val loss = 5.38902 / 5.42342, acc = 74.48980 / 85.13514\n","00:08:33 epoch:  44, train/val loss = 4.40391 / 4.22790, acc = 80.61224 / 82.43243\n","00:08:44 epoch:  45, train/val loss = 4.97803 / 5.00845, acc = 76.87075 / 72.97297\n","00:08:55 epoch:  46, train/val loss = 4.40079 / 4.72660, acc = 82.31293 / 72.97297\n","00:09:07 epoch:  47, train/val loss = 4.80642 / 7.63157, acc = 78.91156 / 64.86486\n","00:09:18 epoch:  48, train/val loss = 4.80205 / 5.59412, acc = 77.21088 / 83.78378\n","00:09:29 epoch:  49, train/val loss = 4.72513 / 5.67446, acc = 80.61224 / 74.32432\n","00:09:41 epoch:  50, train/val loss = 4.92530 / 4.46798, acc = 78.91156 / 70.27027\n","00:09:53 epoch:  51, train/val loss = 4.88419 / 5.25768, acc = 77.89116 / 85.13514\n","00:10:03 epoch:  52, train/val loss = 5.02859 / 4.24101, acc = 76.19048 / 86.48649\n","00:10:14 epoch:  53, train/val loss = 4.74814 / 5.48111, acc = 79.59184 / 71.62162\n","00:10:26 epoch:  54, train/val loss = 5.22848 / 3.94892, acc = 74.14966 / 78.37838\n","00:10:38 epoch:  55, train/val loss = 4.96472 / 4.54099, acc = 74.82993 / 81.08108\n","00:10:49 epoch:  56, train/val loss = 4.87896 / 4.44984, acc = 76.53061 / 79.72973\n","00:11:00 epoch:  57, train/val loss = 5.11052 / 4.39886, acc = 75.51020 / 78.37838\n","00:11:11 epoch:  58, train/val loss = 4.81389 / 4.32702, acc = 78.23129 / 78.37838\n","00:11:22 epoch:  59, train/val loss = 4.97608 / 6.40212, acc = 76.53061 / 75.67568\n","00:11:34 epoch:  60, train/val loss = 4.38339 / 4.89978, acc = 80.27211 / 79.72973\n","00:11:45 epoch:  61, train/val loss = 4.71821 / 4.64396, acc = 78.23129 / 83.78378\n","00:11:57 epoch:  62, train/val loss = 4.73439 / 5.30098, acc = 78.23129 / 67.56757\n","00:12:08 epoch:  63, train/val loss = 5.02251 / 4.90705, acc = 76.87075 / 83.78378\n","00:12:20 epoch:  64, train/val loss = 4.48429 / 3.14523, acc = 79.59184 / 83.78378\n","00:12:31 epoch:  65, train/val loss = 5.24840 / 6.41687, acc = 74.14966 / 72.97297\n","00:12:42 epoch:  66, train/val loss = 4.87327 / 4.34125, acc = 77.89116 / 82.43243\n","00:12:53 epoch:  67, train/val loss = 4.48555 / 6.04102, acc = 80.61224 / 70.27027\n","00:13:05 epoch:  68, train/val loss = 4.63564 / 5.61926, acc = 80.95238 / 75.67568\n","00:13:16 epoch:  69, train/val loss = 4.65966 / 4.64229, acc = 80.27211 / 81.08108\n","00:13:28 epoch:  70, train/val loss = 4.21940 / 5.58966, acc = 81.29252 / 82.43243\n","00:13:39 epoch:  71, train/val loss = 4.86344 / 4.84755, acc = 77.21088 / 71.62162\n","00:13:50 epoch:  72, train/val loss = 3.87982 / 5.29338, acc = 84.01361 / 75.67568\n","00:14:01 epoch:  73, train/val loss = 4.09263 / 4.42799, acc = 82.65306 / 82.43243\n","00:14:13 epoch:  74, train/val loss = 4.22773 / 4.42319, acc = 80.61224 / 78.37838\n","Val losses doesn`t decrease!\n","00:14:24 epoch:  75, train/val loss = 4.64332 / 4.15936, acc = 76.87075 / 87.83784\n","00:14:36 epoch:  76, train/val loss = 4.63850 / 6.43475, acc = 78.23129 / 74.32432\n","00:14:47 epoch:  77, train/val loss = 4.32268 / 5.43515, acc = 80.27211 / 81.08108\n","00:14:58 epoch:  78, train/val loss = 4.41047 / 5.28299, acc = 80.95238 / 72.97297\n","00:15:09 epoch:  79, train/val loss = 4.80926 / 3.97668, acc = 75.17007 / 81.08108\n","00:15:21 epoch:  80, train/val loss = 3.95154 / 6.04948, acc = 83.33333 / 74.32432\n","00:15:33 epoch:  81, train/val loss = 4.70818 / 6.24828, acc = 77.55102 / 68.91892\n","00:15:44 epoch:  82, train/val loss = 4.15803 / 3.61955, acc = 82.99320 / 82.43243\n","00:15:56 epoch:  83, train/val loss = 4.66548 / 7.48488, acc = 77.89116 / 63.51351\n","00:16:07 epoch:  84, train/val loss = 4.39790 / 5.45210, acc = 81.29252 / 78.37838\n","00:16:18 epoch:  85, train/val loss = 4.40835 / 2.96726, acc = 78.57143 / 85.13514\n","00:16:29 epoch:  86, train/val loss = 4.52399 / 5.06657, acc = 75.51020 / 77.02703\n","00:16:40 epoch:  87, train/val loss = 4.19599 / 3.82977, acc = 80.27211 / 78.37838\n","00:16:52 epoch:  88, train/val loss = 3.85928 / 5.51631, acc = 81.63265 / 74.32432\n","00:17:03 epoch:  89, train/val loss = 4.10447 / 4.76195, acc = 81.97279 / 81.08108\n","00:17:15 epoch:  90, train/val loss = 4.37088 / 4.54687, acc = 78.57143 / 79.72973\n","00:17:27 epoch:  91, train/val loss = 4.27539 / 6.31017, acc = 82.31293 / 72.97297\n","00:17:37 epoch:  92, train/val loss = 3.98883 / 6.08174, acc = 81.97279 / 77.02703\n","00:17:48 epoch:  93, train/val loss = 4.24756 / 5.99232, acc = 80.95238 / 74.32432\n","00:18:00 epoch:  94, train/val loss = 4.54438 / 4.91898, acc = 78.23129 / 77.02703\n","00:18:12 epoch:  95, train/val loss = 5.16149 / 6.29497, acc = 74.48980 / 67.56757\n","Val losses doesn`t decrease!\n","00:18:23 epoch:  96, train/val loss = 4.30852 / 4.32661, acc = 79.59184 / 74.32432\n","00:18:35 epoch:  97, train/val loss = 4.60742 / 4.43737, acc = 79.25170 / 78.37838\n","Val losses doesn`t decrease!\n","00:18:46 epoch:  98, train/val loss = 4.17697 / 5.73834, acc = 80.95238 / 77.02703\n","00:18:57 epoch:  99, train/val loss = 4.47710 / 4.71783, acc = 77.55102 / 79.72973\n"]}]},{"cell_type":"markdown","source":["# strokes"],"metadata":{"id":"Qh9HAvTXmUaE"}},{"cell_type":"code","source":["PAD_ID = -1\n","\n","def pad_collate(batch):\n","    # BATCH_SIZE * C * EMB_SIZE x SEQ_LEN\n","    list_tensors, list_targets = zip(*batch)\n","    # print(len(list_tersors), len(list_targets))\n","    # print(list_tersors[0].shape)\n","    ans = [None] * len(list_tensors)\n","    # tokens_len = [None] * len(list_tersors)\n","    # masks = [None] * len(list_tersors)\n","\n","    for i in range(len(list_tensors)):\n","        # tokens_len[i] = list_tensors[i].shape[-1] # SEQ_LEN\n","        ans[i] = list_tensors[i].permute(2, 0, 1) # C x EMB_SIZE x SEQ_LEN -> SEQ_LEN x C x EMB_SIZE\n","\n","    # BATCH_SIZE * SEQ_LEN * C * EMB_SIZE ->\n","    # -> BATCH_SIZE x C x EMB_SIZE x SEQ_LEN\n","    return pad_sequence(ans, batch_first=True, padding_value=PAD_ID).permute(0, 2, 3, 1), torch.tensor(list_targets)"],"metadata":{"id":"GsxtLr0R4boM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NetworkStrokes(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=10, emb_size=18, hid_size=128, output_emb = 1000, num_layers=1):\n","        super().__init__()\n","        self.CNN = nn.Sequential(\n","                     nn.Conv2d(in_channels=in_channels, out_channels=3, kernel_size=3),\n","                     nn.BatchNorm2d(3),\n","                     nn.ReLU(),\n","                     nn.MaxPool2d(kernel_size=2, stride=(2, 3)),\n","\n","                     nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3),\n","                     nn.BatchNorm2d(5),\n","                     nn.ReLU(),\n","                     nn.MaxPool2d(kernel_size=2, stride=(1, 3)),\n","\n","                     nn.Conv2d(in_channels=5, out_channels=out_channels, kernel_size=3),\n","                     nn.BatchNorm2d(10),\n","                     nn.ReLU(),\n","                     nn.MaxPool2d(kernel_size=2, stride=(1, 2)),\n","                     )\n","\n","        self.linear = nn.Linear(out_channels, 1)\n","\n","        self.LSTM = nn.LSTM(input_size=emb_size, # emb_size зависит от CNN\n","                            hidden_size=hid_size,\n","                            num_layers=num_layers,\n","                            batch_first=True)\n","\n","        self.classifier = nn.Sequential(nn.Linear(hid_size, output_emb))\n","\n","    def forward(self, x):\n","        # x ~ BATCH_SIZE x C x EMB_SIZE x SEQ_LEN\n","        # tokens_lens ~ BATCH_SIZE\n","        mask = (x != PAD_ID).int()\n","        # print(x.shape, mask.shape)\n","        # print(1, x.shape)\n","        x = self.CNN(x) # BATCH_SIZE x out_channels x EMB_SIZE_new x SEQ_LEN_new\n","        # print(2, x.shape)\n","        x = x.permute(0, 2, 3, 1) # BATCH_SIZE x EMB_SIZE_new x SEQ_LEN_new x out_channels\n","        x = self.linear(x).squeeze() # BATCH_SIZE x EMB_SIZE_new x SEQ_LEN_new\n","        x = x.permute(0, 2, 1) # BATCH_SIZE x SEQ_LEN_new x EMB_SIZE_new\n","\n","\n","        mask = mask[:, 0, 0, ::18] # BATCH_SIZE x SEQ_LEN_new\n","        mask = mask[:, :x.shape[1]]\n","\n","        # print(3, x.shape)\n","        x, _ = self.LSTM(x) # BATCH_SIZE x SEQ_LEN_new x HIDDEN_SIZE\n","\n","        # print(x.shape, mask.shape)\n","        x = x * mask[..., None] # BATCH_SIZE x SEQ_LEN_new x HIDDEN_SIZE\n","\n","        sum = x.sum(dim = 1) # BATCH_SIZE x HIDDEN_SIZE\n","        col = mask.sum(dim = 1) # BATCH_SIZE\n","\n","        x = sum / col[..., None]\n","        # x = x.mean(dim = 1)\n","        # last_hid_idxs = (tokens_lens / 18).to(int) - 1\n","        # last_hid_idxs = (tokens_lens / 18).to(int) - 5\n","        # x = x[torch.arange(len(tokens_lens)), last_hid_idxs - 1, :] # BATCH_SIZE x HIDDEN_SIZE\n","        # BATCH_SIZE x HIDDEN_SIZE\n","        return self.classifier(x)\n"],"metadata":{"id":"phcaK-pvLR_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = My_Dataset(\"КККМfolder3_strokes_bin\", transform=transforms.ToTensor())\n","dataset.dir2count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lduTtuACvWRf","executionInfo":{"status":"ok","timestamp":1744024221741,"user_tz":-180,"elapsed":73,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"d81d2798-2e95-45b4-90ad-949f082e126a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Ивановский Алексей Осипович': 610,\n"," 'Потанина Александра Викторовна': 647,\n"," 'Фарафонтова Таисия Михайловна': 641}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["transform = transforms.Compose(\n","    [\n","            transforms.ToTensor(),\n","            Min_size(50),\n","\n","    ])\n","\n","\n","model = NetworkStrokes().to(DEVICE)\n","print(f\"Parameters number: {number_of_parameters(model)}\")\n","dataset = My_Dataset(\"КККМfolder3_strokes_bin\", transform)\n","dataset.dir2count\n","test_pipeline(model, dataset, pad_collate, DEVICE, batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AX5Ng7CDsGNQ","executionInfo":{"status":"ok","timestamp":1744024227571,"user_tz":-180,"elapsed":4213,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"9c0cb314-414d-4f60-c258-15bcdf6c6449"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameters number: 205507\n","X_batch: torch.Size([64, 3, 50, 700])\n","y_batch: torch.Size([64])\n","model:   torch.Size([64, 1000])\n"]}]},{"cell_type":"code","source":["img, cls = dataset[7]\n","img = img.permute(1, 2, 0)\n","\n","plt.figure(figsize=(5, 1))\n","plt.imshow(img, cmap=\"grey\")\n","plt.title(f\"{img.shape} {cls}\")\n","plt.axis(False)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":92},"id":"NALd6AClvN-q","executionInfo":{"status":"ok","timestamp":1744022897835,"user_tz":-180,"elapsed":338,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"52b42c72-859c-4e73-a8f6-4596f3ef27e9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 500x100 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["cl_model = NetworkStrokes().to(DEVICE).to(DEVICE)\n","print(f\"Parameters number: {number_of_parameters(cl_model)}\")\n","\n","# transform = transforms.ToTensor()\n","transform = transforms.Compose(\n","    [\n","            transforms.ToTensor(),\n","            Min_size(50),\n","    ])\n","\n","dataset = My_Dataset(\"КККМfolder3_strokes_bin\", transform)\n","print(len(dataset))\n","train_dataset, test_dataset = split_dataset(dataset)\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","optimizer = torch.optim.Adam(cl_model.parameters(), lr=3e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","BATCH_SIZE = 64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_collate)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_collate)\n","\n","trainer = Trainer(cl_model, optimizer, criterion, type = \"not siam\", dir = \"logs\", name = \"strokes_cl3\")\n","\n","trainer.train(train_loader, val_loader, n_epochs = 20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432,"referenced_widgets":["234e6a3ed8dd494f84a1d6f19df4b966","120f57d52a7f4ecc8b37774b9cfcbd39","4a62a819afa5423ea4352956a058b6e8","24f2024fff634ad5b6793b924b0261be","8b660ac9579d4dc0934e8f3447c95a1b","d4ca7fff732f4e9ab5a28d7726207bdd","052ec5a235714257a515ff92fa24aeea","ba88739af5b44933a01f748e1904a526","27fd7f9b993e48bab58cbe7c9b1a27e0","0f93eaeeb03b4553984c6c3735654848","18f15d6c2290483db0f4ba21a46f2f4f"]},"id":"agKXjvuN72ZT","executionInfo":{"status":"error","timestamp":1744024520038,"user_tz":-180,"elapsed":74498,"user":{"displayName":"Наталия","userId":"03780066343814609442"}},"outputId":"54ff69b9-8f77-4c3c-df80-e70b567938a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameters number: 205507\n","1898\n","split_dataset: Train: 1518 Test: 380 Total: 1898\n","train dataset: 1518, test dataset: 380\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"234e6a3ed8dd494f84a1d6f19df4b966"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-40cd02a05186>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"not siam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"logs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"strokes_cl3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-b1cd8007430f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader, n_epochs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-b1cd8007430f>\u001b[0m in \u001b[0;36m_train_step\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-c1b2990dd89f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3474\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3476\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"KvdasOob77MM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hU5TLLCy77P8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Device: {DEVICE}\")\n","\n","model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(DEVICE)\n","emb_dim = 1000\n","model = create_model(model, num_freeze_layers=9, num_out_classes=emb_dim).to(DEVICE)\n","print(f\"Parameters number: {number_of_parameters(model)}\")\n","\n","# transform = transforms.ToTensor()\n","transform = transforms.Compose(\n","    [\n","            transforms.RandomCrop(300),\n","            transforms.CenterCrop(224),\n","            # transforms.RandomPerspective(distortion_scale=0.5, p=0.5, fill=255),\n","            transforms.ToTensor(),\n","    ])\n","\n","\n","dataset = My_TripletDataset(\"КККМfolder3_bin\", transform)\n","print(len(dataset))\n","train_dataset, test_dataset = split_dataset(dataset)\n","print(f\"train dataset: {len(train_dataset)}, test dataset: {len(test_dataset)}\")\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n","criterion = torch.nn.TripletMarginLoss(margin=9, p=2)\n","\n","BATCH_SIZE = 64\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","trainer = Trainer(model, optimizer, criterion, type = \"siam\", dir = \"logs\", name = \"siam3\")\n","\n","trainer.train(train_loader, val_loader, n_epochs = 30)"],"metadata":{"id":"-Y7ACiqf4Jac"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.0"},"colab":{"provenance":[],"toc_visible":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"8c4862c8d0594a7c988f3d593934c71b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fafe60b71e50487bba675f51b3657ebd","IPY_MODEL_c25f73a9ca3846c59893c9af088e9541","IPY_MODEL_be518a0b8d6f4d5698082fc99eae1e02"],"layout":"IPY_MODEL_4652dbda94f946339eb3f07b582eff54"}},"fafe60b71e50487bba675f51b3657ebd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8e8ca5734524db7a1194cdf617393d3","placeholder":"​","style":"IPY_MODEL_621e2bc91657468492828d975c45e135","value":"100%"}},"c25f73a9ca3846c59893c9af088e9541":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40ac9804a9d1490b88382b8041979768","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_251c8586be294ae9a36ba14f99cbfa92","value":100}},"be518a0b8d6f4d5698082fc99eae1e02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93faf19a9bd5428683e6518756fb6c4d","placeholder":"​","style":"IPY_MODEL_e0c5d7a585184d1e9fff9b2817e8cb32","value":" 100/100 [18:58&lt;00:00, 11.39s/it]"}},"4652dbda94f946339eb3f07b582eff54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8e8ca5734524db7a1194cdf617393d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"621e2bc91657468492828d975c45e135":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40ac9804a9d1490b88382b8041979768":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"251c8586be294ae9a36ba14f99cbfa92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93faf19a9bd5428683e6518756fb6c4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0c5d7a585184d1e9fff9b2817e8cb32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0d2939eb5264e7f9a3f27eec2dd4d3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49ec89dfb307456b807927de0f33ec5e","IPY_MODEL_e1ac41976b104da08a1cb594d72534ca","IPY_MODEL_b1460c57d9654f0cac9833e797bc0364"],"layout":"IPY_MODEL_d227394f5cc542e9a775f0a32ed1c21f"}},"49ec89dfb307456b807927de0f33ec5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4aa25146b7764f45a536bbb6063b8708","placeholder":"​","style":"IPY_MODEL_dae1e57f52cb48749f7466bc8106133d","value":"100%"}},"e1ac41976b104da08a1cb594d72534ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1dc23d5b32b49d0990f58b2c8e6922f","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee62a2ff1106476593b737a397f760b1","value":30}},"b1460c57d9654f0cac9833e797bc0364":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edca847ed5de450a91c9a88a4fa6d5f5","placeholder":"​","style":"IPY_MODEL_7cb200ebd2314ea28a6dc4e52a291249","value":" 30/30 [05:21&lt;00:00, 10.61s/it]"}},"d227394f5cc542e9a775f0a32ed1c21f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aa25146b7764f45a536bbb6063b8708":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dae1e57f52cb48749f7466bc8106133d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1dc23d5b32b49d0990f58b2c8e6922f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee62a2ff1106476593b737a397f760b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"edca847ed5de450a91c9a88a4fa6d5f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cb200ebd2314ea28a6dc4e52a291249":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bcd134bc68d4729a9ee226424bc8486":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a9cb8b87c1141798b434de4605ccd62","IPY_MODEL_3390b8bfcd4d430ea0911cbfa196993e","IPY_MODEL_1f3d91a549ce48329e0fefb86a29aed4"],"layout":"IPY_MODEL_54b1d618a2fa455fad0fdab20e2d6fa9"}},"5a9cb8b87c1141798b434de4605ccd62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfa17ad8ab824af0b14aa2a2f330a1bd","placeholder":"​","style":"IPY_MODEL_6e4e72b0b9dd411982e9b37e68996ca8","value":"100%"}},"3390b8bfcd4d430ea0911cbfa196993e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_428a765e25f74788a535e7961a281e05","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3af4320e852742dfbd70472121f0cf89","value":20}},"1f3d91a549ce48329e0fefb86a29aed4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30de8e939f8d420293c45b6b56b43010","placeholder":"​","style":"IPY_MODEL_9a781d596ac142c192e4b31968d768d1","value":" 20/20 [01:28&lt;00:00,  4.48s/it]"}},"54b1d618a2fa455fad0fdab20e2d6fa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfa17ad8ab824af0b14aa2a2f330a1bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e4e72b0b9dd411982e9b37e68996ca8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"428a765e25f74788a535e7961a281e05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3af4320e852742dfbd70472121f0cf89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30de8e939f8d420293c45b6b56b43010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a781d596ac142c192e4b31968d768d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a54ce8492ede4436b6da22f462e26926":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a671a821b48f4bf29c36f3234e75499a","IPY_MODEL_c4c13f039d1e4bac98512e5fa5c0d348","IPY_MODEL_93edf958eb8f45a4aecb598e5e02976a"],"layout":"IPY_MODEL_1968c0f8deca4ccc9e637f2ec786e12c"}},"a671a821b48f4bf29c36f3234e75499a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9e74f52d846484fba7f6a595fc891da","placeholder":"​","style":"IPY_MODEL_5f155a8226b2459f8c160ccb0230b4f4","value":"100%"}},"c4c13f039d1e4bac98512e5fa5c0d348":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0062c8b87314b8793f30c8ef32171ee","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db43fc4045cb489ebe723786695cd30b","value":30}},"93edf958eb8f45a4aecb598e5e02976a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4668cd71ef44df8a22c13e26c7f247c","placeholder":"​","style":"IPY_MODEL_7738aa829a49445c9ecbe6284aaa6a4e","value":" 30/30 [02:59&lt;00:00,  5.69s/it]"}},"1968c0f8deca4ccc9e637f2ec786e12c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9e74f52d846484fba7f6a595fc891da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f155a8226b2459f8c160ccb0230b4f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0062c8b87314b8793f30c8ef32171ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db43fc4045cb489ebe723786695cd30b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4668cd71ef44df8a22c13e26c7f247c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7738aa829a49445c9ecbe6284aaa6a4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70b4c0286c8e473380180ac0c8907149":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7800e95fbc147d7aa48f8d31c28ee00","IPY_MODEL_9ce10aab4f954c9391e25e806f226d7e","IPY_MODEL_76e689ca4afe41fca51bda02fdaa5ac8"],"layout":"IPY_MODEL_987dd545dc174c06b719c4adbec75a53"}},"f7800e95fbc147d7aa48f8d31c28ee00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37f56d1153054aceb575d2c12ed26d79","placeholder":"​","style":"IPY_MODEL_fc954db258b3488eb60dd8776659b3a7","value":"100%"}},"9ce10aab4f954c9391e25e806f226d7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_135e17457f16455398e487fa958f6945","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff71b597b95543bd98a14f2eaef8e5de","value":20}},"76e689ca4afe41fca51bda02fdaa5ac8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e6451b07ff242fb89fefc3769246287","placeholder":"​","style":"IPY_MODEL_904446c2111940a9bf093d4b5f2eb959","value":" 20/20 [00:41&lt;00:00,  2.15s/it]"}},"987dd545dc174c06b719c4adbec75a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37f56d1153054aceb575d2c12ed26d79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc954db258b3488eb60dd8776659b3a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"135e17457f16455398e487fa958f6945":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff71b597b95543bd98a14f2eaef8e5de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e6451b07ff242fb89fefc3769246287":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"904446c2111940a9bf093d4b5f2eb959":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"234e6a3ed8dd494f84a1d6f19df4b966":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_120f57d52a7f4ecc8b37774b9cfcbd39","IPY_MODEL_4a62a819afa5423ea4352956a058b6e8","IPY_MODEL_24f2024fff634ad5b6793b924b0261be"],"layout":"IPY_MODEL_8b660ac9579d4dc0934e8f3447c95a1b"}},"120f57d52a7f4ecc8b37774b9cfcbd39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4ca7fff732f4e9ab5a28d7726207bdd","placeholder":"​","style":"IPY_MODEL_052ec5a235714257a515ff92fa24aeea","value":"  0%"}},"4a62a819afa5423ea4352956a058b6e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba88739af5b44933a01f748e1904a526","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27fd7f9b993e48bab58cbe7c9b1a27e0","value":0}},"24f2024fff634ad5b6793b924b0261be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f93eaeeb03b4553984c6c3735654848","placeholder":"​","style":"IPY_MODEL_18f15d6c2290483db0f4ba21a46f2f4f","value":" 0/20 [01:14&lt;?, ?it/s]"}},"8b660ac9579d4dc0934e8f3447c95a1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4ca7fff732f4e9ab5a28d7726207bdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"052ec5a235714257a515ff92fa24aeea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba88739af5b44933a01f748e1904a526":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27fd7f9b993e48bab58cbe7c9b1a27e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f93eaeeb03b4553984c6c3735654848":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18f15d6c2290483db0f4ba21a46f2f4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}